{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8eDqH1GDLxD"
      },
      "source": [
        "### Train bs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rw2M9bMOE78_"
      },
      "outputs": [],
      "source": [
        "!pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WECRMTJIGk2n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Torch GPU setting\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJ5sU07rz7cn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "\n",
        "base_path = 'BS-Detect/working_dir/dataset/final/'\n",
        "def words_counter(testo):\n",
        "    parole = re.findall(r'\\w+', str(testo))\n",
        "    return len(parole)\n",
        "\n",
        "df = pd.read_excel(f'{base_path}balanced_dataset.xlsx')\n",
        "df['words_n'] = df['comment'].apply(words_counter)\n",
        "\n",
        "# Calcola la media del numero di parole\n",
        "words_mean = df['words_n'].mean()\n",
        "\n",
        "\n",
        "print(\"mean number:\", words_mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLnhAhqU4q_I"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['comment'].values\n",
        "y = df['bs'].replace({'1': 1, '0': 0}).values\n",
        "train_sentences, eval_sentences, train_labels, eval_labels = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "424a4nuR17ah"
      },
      "outputs": [],
      "source": [
        "# BERT tokenizer: To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "huggingface_model_name = 'Musixmatch/umberto-commoncrawl-cased-v1'\n",
        "#huggingface_model_name = 'm-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0'\n",
        "#huggingface_model_name = 'FacebookAI/xlm-roberta-base'\n",
        "\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "print('Loading tokenizer...')\n",
        "tokenizer = AutoTokenizer.from_pretrained(huggingface_model_name)  # it will download and save it in a cache local directory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dy7OXNAx4iWr"
      },
      "outputs": [],
      "source": [
        "max_length = 32\n",
        "num_labels = 2\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "train_lab_tensor = torch.zeros((len(train_sentences), num_labels))\n",
        "\n",
        "for i, sent in enumerate(train_sentences):\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = max_length,           # Pad & truncate all sentences.\n",
        "                        padding='max_length',\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        truncation=True,\n",
        "                   )\n",
        "\n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    # add label to lab_tensor\n",
        "    if train_labels[i] <= float(num_labels):\n",
        "      train_lab_tensor[i, int(train_labels[i])] = 1\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "train_input_ids = torch.cat(input_ids, dim=0)\n",
        "train_attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "\n",
        "# let's encode the evaluation dataset\n",
        "\n",
        "max_length = 32 # instead of 47, just in case there are some longer test sentences\n",
        "num_labels = 2\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "eval_lab_tensor = torch.zeros((len(eval_sentences), num_labels))\n",
        "\n",
        "# For every sentence...\n",
        "for i, sent in enumerate(eval_sentences):\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = max_length,           # Pad & truncate all sentences.\n",
        "                        padding='max_length',\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                        truncation=True,\n",
        "                   )\n",
        "\n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    # add label to lab_tensor\n",
        "    if eval_labels[i] <= float(num_labels):\n",
        "      eval_lab_tensor[i, int(eval_labels[i])] = 1\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "eval_input_ids = torch.cat(input_ids, dim=0)\n",
        "eval_attention_masks = torch.cat(attention_masks, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EE5wjGni8rYu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import IterableDataset\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "\n",
        "class MyDataLoader(IterableDataset):\n",
        "\n",
        "  def __init__(self, ids, mask, labels):\n",
        "    super(MyDataLoader).__init__()\n",
        "    self._ids = ids\n",
        "    self._mask = mask\n",
        "    self._labels = labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return self._ids.size(dim=0)\n",
        "  def __iter__(self):\n",
        "    for idx in range(len(self)):\n",
        "        item = dict()\n",
        "        item[\"input_ids\"] = torch.Tensor(self._ids[idx])\n",
        "        item[\"attention_mask\"] = torch.Tensor(self._mask[idx])\n",
        "        item[\"labels\"] = self._labels[idx, :]\n",
        "        yield item\n",
        "  def __getitem__(self, idx):\n",
        "    item = dict()\n",
        "    item[\"input_ids\"] = torch.Tensor(self._ids[idx])\n",
        "    item[\"attention_mask\"] = torch.Tensor(self._mask[idx])\n",
        "    item[\"labels\"] = self._labels[idx, :]\n",
        "    return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwtf-Tf39Rj4"
      },
      "outputs": [],
      "source": [
        "# training and validation split - 90% train and 20% valid\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "trainset = MyDataLoader(train_input_ids, train_attention_masks, train_lab_tensor)\n",
        "evalset = MyDataLoader(eval_input_ids, eval_attention_masks, eval_lab_tensor)\n",
        "\n",
        "trainset, _ = random_split(trainset, [len(trainset), 0])\n",
        "evalset, _ = random_split(evalset,  [len(evalset), 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBJc7Xaf9FaP"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it\n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch\n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order.\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "            trainset,  # The training samples.\n",
        "            sampler=RandomSampler(trainset),\n",
        "            batch_size = batch_size # Train with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            evalset, # The validation samples.\n",
        "            sampler=SequentialSampler(evalset),\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALoIsI5gEGuu"
      },
      "outputs": [],
      "source": [
        "# define the model - we will use BERTForSequenceClassification because it has the same BERT architecture but with a single classification layer on top\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single\n",
        "# linear classification layer on top.\n",
        "\n",
        "def my_model_init():\n",
        "  model = AutoModelForSequenceClassification.from_pretrained(\n",
        "      huggingface_model_name,\n",
        "      num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                      # You can increase this for multi-class tasks.\n",
        "      output_attentions = False, # Whether the model returns attentions weights.\n",
        "      output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "      return_dict=True\n",
        "  )\n",
        "\n",
        "  for name, param in model.named_parameters():\n",
        "    if 'Bert' in name:\n",
        "      param.requires_grad = False\n",
        "\n",
        "  model.to(device)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJ3MrYTcENCt"
      },
      "outputs": [],
      "source": [
        "from transformers import EvalPrediction\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, accuracy_score\n",
        "\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "  y_true = p.label_ids\n",
        "  preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "\n",
        "  y_pred = preds.argmax(-1)\n",
        "  y_true = y_true.argmax(-1)\n",
        "\n",
        "\n",
        "  new_df = pd.DataFrame( )\n",
        "  new_df['pred_label'] = y_pred\n",
        "  new_df['true_label'] = y_true\n",
        "  new_df.to_csv(f'{base_path}{huggingface_model_name}/bs/predictions.csv', header=True)\n",
        "\n",
        "  precision = precision_score(y_true=y_true, y_pred=y_pred, average='macro',zero_division = 'warn')\n",
        "  recall = recall_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
        "  f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
        "  #roc_auc = roc_auc_score(y_true, y_pred, average='micro', multi_class='ovo')\n",
        "\n",
        "  accuracy = accuracy_score(y_true, y_pred)\n",
        "  metrics = {'p': precision,\n",
        "            'r': recall,\n",
        "            'f1': f1_micro_average,\n",
        "            #'roc_auc': roc_auc,\n",
        "            'accuracy': accuracy}\n",
        "  return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztZNyMqZjjPy"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainerCallback\n",
        "\n",
        "class EarlyStoppingCallback(TrainerCallback):\n",
        "    def __init__(self, patience=3):\n",
        "        self.patience = patience\n",
        "        self.best_metric = float('inf')\n",
        "        self.counter = 0\n",
        "\n",
        "    def on_evaluate(self, args, state, control, **kwargs):\n",
        "        metrics = state.log_history[-1]\n",
        "        metric = metrics[\"eval_loss\"]\n",
        "        if metric < self.best_metric:\n",
        "            self.best_metric = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                control.should_training_stop = True\n",
        "\n",
        "early_stopping_callback = EarlyStoppingCallback(patience=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZy-9-_VEPIJ"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "num_epochs = 30\n",
        "\n",
        "lr = 5e-5\n",
        "eps= 2e-10\n",
        "adam_beta_1 = 0.9\n",
        "adam_beta_2 = 0.999\n",
        "warmup_steps = int(len(trainset) * num_epochs * 0.2)\n",
        "\n",
        "out_dir = f'{base_path}{huggingface_model_name}/original'\n",
        "num_saved_models = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDKpq0ohEwAt"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(output_dir=out_dir,\n",
        "                                  overwrite_output_dir=True,\n",
        "                                  do_train=True,\n",
        "                                  do_eval=True,\n",
        "                                  #do_test=True,\n",
        "                                  do_predict=True,\n",
        "                                  fp16=True,\n",
        "                                  evaluation_strategy='epoch',\n",
        "                                  per_device_train_batch_size=batch_size,\n",
        "                                  per_device_eval_batch_size=batch_size,\n",
        "                                  learning_rate=lr,\n",
        "                                  #adam_beta1=adam_beta_1,\n",
        "                                  #adam_beta2=adam_beta_2,\n",
        "                                  adam_epsilon=eps,\n",
        "                                  lr_scheduler_type='linear',\n",
        "                                  warmup_steps=warmup_steps,\n",
        "                                  num_train_epochs=num_epochs,\n",
        "                                  save_strategy='epoch',\n",
        "                                  save_total_limit=num_saved_models,\n",
        "                                  load_best_model_at_end=True,\n",
        "                                  metric_for_best_model='p',\n",
        "                                  logging_strategy='epoch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOsfb20lGWep"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model_init=my_model_init,\n",
        "    args=training_args,\n",
        "    train_dataset=trainset,\n",
        "    eval_dataset=evalset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[early_stopping_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLYmxvdaGr6D"
      },
      "outputs": [],
      "source": [
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fnghc09KM5Rg"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate(evalset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmdYStJMC8DJ"
      },
      "source": [
        "### Labels Second Task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9taupkbuDUdO"
      },
      "outputs": [],
      "source": [
        "!pip install transformers[torch]\n",
        "\n",
        "import torch\n",
        "\n",
        "# Torch GPU setting\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdjGisTcFQTc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import IterableDataset\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "from transformers import EvalPrediction\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, accuracy_score\n",
        "\n",
        "\n",
        "batch_size = 16\n",
        "num_epochs = 30\n",
        "\n",
        "lr = 1e-5\n",
        "eps= 2e-10\n",
        "adam_beta_1 = 0.9\n",
        "adam_beta_2 = 0.999\n",
        "\n",
        "class MyDataLoader(IterableDataset):\n",
        "\n",
        "  def __init__(self, ids, mask, labels):\n",
        "    super(MyDataLoader).__init__()\n",
        "    self._ids = ids\n",
        "    self._mask = mask\n",
        "    self._labels = labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return self._ids.size(dim=0)\n",
        "  def __iter__(self):\n",
        "    for idx in range(len(self)):\n",
        "        item = dict()\n",
        "        item[\"input_ids\"] = torch.Tensor(self._ids[idx])\n",
        "        item[\"attention_mask\"] = torch.Tensor(self._mask[idx])\n",
        "        item[\"labels\"] = self._labels[idx, :]\n",
        "        yield item\n",
        "  def __getitem__(self, idx):\n",
        "    item = dict()\n",
        "    item[\"input_ids\"] = torch.Tensor(self._ids[idx])\n",
        "    item[\"attention_mask\"] = torch.Tensor(self._mask[idx])\n",
        "    item[\"labels\"] = self._labels[idx, :]\n",
        "    return item\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def my_model_init():\n",
        "  model = AutoModelForSequenceClassification.from_pretrained(        # use DistilBertForSequenceClassification if you want\n",
        "      huggingface_model_name,\n",
        "      num_labels = 2,\n",
        "      output_attentions = False,\n",
        "      output_hidden_states = False,\n",
        "      return_dict=True\n",
        "  )\n",
        "\n",
        "  for name, param in model.named_parameters():\n",
        "    if 'Bert' in name:\n",
        "      param.requires_grad = False\n",
        "\n",
        "  model.to(device)\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "  y_true = p.label_ids\n",
        "  preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "\n",
        "  y_pred = preds.argmax(-1)\n",
        "  y_true = y_true.argmax(-1)\n",
        "\n",
        "  precision = precision_score(y_true=y_true, y_pred=y_pred, average='macro',zero_division = 'warn')\n",
        "  recall = recall_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
        "  f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
        "\n",
        "  accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "  metrics = {'p': precision,\n",
        "            'r': recall,\n",
        "            'f1': f1_micro_average,\n",
        "            'accuracy': accuracy}\n",
        "  return metrics\n",
        "\n",
        "\n",
        "from transformers import TrainerCallback\n",
        "\n",
        "class EarlyStoppingCallback(TrainerCallback):\n",
        "    def __init__(self, patience=3):\n",
        "        self.patience = patience\n",
        "        self.best_metric = float('inf')\n",
        "        self.counter = 0\n",
        "\n",
        "    def on_evaluate(self, args, state, control, **kwargs):\n",
        "        metrics = state.log_history[-1]\n",
        "        metric = metrics[\"eval_loss\"]\n",
        "        if metric < self.best_metric:\n",
        "            self.best_metric = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                control.should_training_stop = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vW8Ir3ehDjCf"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "\n",
        "base_path = 'BS-detect/working_dir/dataset/final/'\n",
        "\n",
        "df = pd.read_excel(f'{base_path}balanced_dataset.xlsx')\n",
        "df = df.loc[df['bs'] == 1]\n",
        "targets = ['fatphobia', 'skinny-shaming','misoginy/sexism',\n",
        "         'racism', 'ableism', 'queerphobia']\n",
        "\n",
        "for target in targets:\n",
        "\n",
        "  X = df['comment'].values\n",
        "  y = df[target].replace({'1': 1, '0': 0}).values\n",
        "  train_sentences, eval_sentences, train_labels, eval_labels = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "  huggingface_model_name = 'Musixmatch/umberto-commoncrawl-cased-v1'\n",
        "  #huggingface_model_name = 'm-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0'\n",
        "  #huggingface_model_name = 'FacebookAI/xlm-roberta-base'\n",
        "\n",
        "  tokenizer = AutoTokenizer.from_pretrained(huggingface_model_name)\n",
        "\n",
        "  max_length = 32\n",
        "  num_labels = 2\n",
        "\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  train_lab_tensor = torch.zeros((len(train_sentences), num_labels))\n",
        "\n",
        "  for i, sent in enumerate(train_sentences):\n",
        "\n",
        "      encoded_dict = tokenizer(\n",
        "                          sent,\n",
        "                          add_special_tokens = True,\n",
        "                          max_length = max_length,\n",
        "                          padding='max_length',\n",
        "                          return_tensors = 'pt',\n",
        "                          truncation=True,\n",
        "                    )\n",
        "\n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "      if train_labels[i] <= float(num_labels):\n",
        "        train_lab_tensor[i, int(train_labels[i])] = 1\n",
        "\n",
        "  train_input_ids = torch.cat(input_ids, dim=0)\n",
        "  train_attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "\n",
        "  max_length = 32\n",
        "  num_labels = 2\n",
        "\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  eval_lab_tensor = torch.zeros((len(eval_sentences), num_labels))\n",
        "\n",
        "  for i, sent in enumerate(eval_sentences):\n",
        "\n",
        "      encoded_dict = tokenizer(\n",
        "                          sent,\n",
        "                          add_special_tokens = True,\n",
        "                          max_length = max_length,\n",
        "                          padding='max_length',\n",
        "                          return_tensors = 'pt',\n",
        "                          truncation=True,\n",
        "                    )\n",
        "\n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "      if eval_labels[i] <= float(num_labels):\n",
        "        eval_lab_tensor[i, int(eval_labels[i])] = 1\n",
        "\n",
        "  eval_input_ids = torch.cat(input_ids, dim=0)\n",
        "  eval_attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "\n",
        "  trainset = MyDataLoader(train_input_ids, train_attention_masks, train_lab_tensor)\n",
        "  evalset = MyDataLoader(eval_input_ids, eval_attention_masks, eval_lab_tensor)\n",
        "\n",
        "  trainset, _ = random_split(trainset, [len(trainset), 0])\n",
        "  evalset, _ = random_split(evalset,  [len(evalset), 0])\n",
        "\n",
        "\n",
        "  batch_size = 16\n",
        "\n",
        "  train_dataloader = DataLoader(\n",
        "              trainset,\n",
        "              sampler=RandomSampler(trainset),\n",
        "              batch_size = batch_size\n",
        "          )\n",
        "\n",
        "  validation_dataloader = DataLoader(\n",
        "              evalset,\n",
        "              sampler=SequentialSampler(evalset),\n",
        "              batch_size = batch_size\n",
        "          )\n",
        "\n",
        "\n",
        "  out_dir = f'{base_path}{huggingface_model_name}/{target}'\n",
        "  num_saved_models = 1\n",
        "\n",
        "  warmup_steps = int(len(trainset) * num_epochs * 0.2)\n",
        "\n",
        "  training_args = TrainingArguments(output_dir=out_dir,\n",
        "                                    overwrite_output_dir=True,\n",
        "                                    do_train=True,\n",
        "                                    do_eval=True,\n",
        "                                    #do_test=True,\n",
        "                                    do_predict=True,\n",
        "                                    fp16=True,\n",
        "                                    evaluation_strategy='epoch',\n",
        "                                    per_device_train_batch_size=batch_size,\n",
        "                                    per_device_eval_batch_size=batch_size,\n",
        "                                    learning_rate=lr,\n",
        "                                    #adam_beta1=adam_beta_1,\n",
        "                                    #adam_beta2=adam_beta_2,\n",
        "                                    adam_epsilon=eps,\n",
        "                                    lr_scheduler_type='linear',\n",
        "                                    #warmup_steps=warmup_steps,\n",
        "                                    num_train_epochs=num_epochs,\n",
        "                                    save_strategy='epoch',\n",
        "                                    save_total_limit=num_saved_models,\n",
        "                                    load_best_model_at_end=True,\n",
        "                                    metric_for_best_model='p',\n",
        "                                    logging_strategy='epoch')\n",
        "\n",
        "  early_stopping_callback = EarlyStoppingCallback(patience=3)\n",
        "\n",
        "  trainer = Trainer(\n",
        "      model_init=my_model_init,\n",
        "      args=training_args,\n",
        "      train_dataset=trainset,\n",
        "      eval_dataset=evalset,\n",
        "      compute_metrics=compute_metrics,\n",
        "      callbacks=[early_stopping_callback]\n",
        "  )\n",
        "\n",
        "  trainer.train()\n",
        "\n",
        "  trainer.evaluate(evalset)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}